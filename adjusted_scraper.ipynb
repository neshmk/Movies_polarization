{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f8d59a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "output_file = \"letterboxd_urls_and_ratings.csv\"\n",
    "\n",
    "# ------------------------\n",
    "# FUNCTION TO SCRAPE DATA\n",
    "# ------------------------\n",
    "\n",
    "def parse_shorthand_number(text): \n",
    "    text = text.lower().replace(\",\", \"\").strip()\n",
    "    if text.endswith(\"k\"):\n",
    "        return int(float(text[:-1]) * 1000)\n",
    "    elif text.endswith(\"m\"):\n",
    "        return int(float(text[:-1]) * 1_000_000)\n",
    "    else:\n",
    "        return int(text)\n",
    "\n",
    "def parse_rating_bar_text(rating_text):\n",
    "    match = re.match(r'([\\d,]+)\\s+([★½]+)', rating_text)\n",
    "    if match:\n",
    "        count = int(match.group(1).replace(',', ''))\n",
    "        stars = match.group(2)\n",
    "        decimal = stars.count('★') + 0.5 * stars.count('½')\n",
    "        return f\"{decimal}★\", count\n",
    "    return None, 0\n",
    "\n",
    "def scrape_movie_data(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Title\n",
    "    try:\n",
    "        title = driver.find_element(By.CLASS_NAME, \"headline-1\").text\n",
    "    except:\n",
    "        title = \"N/A\"\n",
    "\n",
    "    # Director\n",
    "    try:\n",
    "        director = driver.find_element(By.XPATH, '//p[@class=\"credits\"]//span[@class=\"prettify\"]').text\n",
    "    except:\n",
    "        director = \"N/A\"\n",
    "\n",
    "    # Release Year\n",
    "    try:\n",
    "        release_year_elem = driver.find_element(By.CSS_SELECTOR, \"span.releasedate a\")\n",
    "        release_year = release_year_elem.text\n",
    "    except:\n",
    "        release_year = \"N/A\"\n",
    "\n",
    "    # Average Rating\n",
    "    try:\n",
    "        avg_rating = driver.find_element(By.CLASS_NAME, \"average-rating\").text\n",
    "    except:\n",
    "        avg_rating = \"N/A\"\n",
    "\n",
    "    # Individual star rating counts (cleaned into X0.5 - X5.0)\n",
    "    bars = driver.find_elements(By.CSS_SELECTOR, \"li.rating-histogram-bar a\")\n",
    "    rating_dict = {}\n",
    "    for bar in bars:\n",
    "        try:\n",
    "            rating_text = bar.get_attribute(\"data-original-title\")\n",
    "            star, count = parse_rating_bar_text(rating_text)\n",
    "            if star:\n",
    "                rating_dict[star] = count\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # Fill missing with 0\n",
    "    for r in [f\"{x/2:.1f}★\" for x in range(1, 11)]:\n",
    "        rating_dict.setdefault(r, 0)\n",
    "\n",
    "    rating_columns = {f\"X{r}\": rating_dict[f\"{r}★\"] for r in [\"0.5\", \"1.0\", \"1.5\", \"2.0\", \"2.5\", \"3.0\", \"3.5\", \"4.0\", \"4.5\", \"5.0\"]}\n",
    "\n",
    "    # Fans\n",
    "    try: \n",
    "         fans_elem = driver.find_element(By.CSS_SELECTOR, 'section.ratings-histogram-chart a.all-link.more-link')\n",
    "         fans_text = fans_elem.text.split()[0]\n",
    "         fans = parse_shorthand_number(fans_text)\n",
    "    except:\n",
    "        fans = \"N/A\"\n",
    "\n",
    "    # Watched\n",
    "    try:\n",
    "        watched_attr = driver.find_element(\n",
    "            By.XPATH,\n",
    "            '//a[contains(@href, \"/members/\") and contains(@data-original-title, \"Watched by\")]'\n",
    "        ).get_attribute(\"data-original-title\")\n",
    "        watched = re.sub(r\"[^\\d]\", \"\", watched_attr)\n",
    "    except:\n",
    "        watched = \"N/A\"\n",
    "\n",
    "    # Likes\n",
    "    try:\n",
    "        liked_attr = driver.find_element(\n",
    "            By.XPATH,\n",
    "            '//a[contains(@href, \"/likes/\") and contains(@data-original-title, \"Liked by\")]'\n",
    "        ).get_attribute(\"data-original-title\")\n",
    "        liked = re.sub(r\"[^\\d]\", \"\", liked_attr)\n",
    "    except:\n",
    "        liked = \"N/A\"\n",
    "\n",
    "    # Genres\n",
    "    try:\n",
    "        genres = [a.get_attribute(\"textContent\").strip() for a in driver.find_elements(\n",
    "            By.XPATH, '//div[@id=\"tab-genres\"]//h3[span[text()=\"Genres\"]]/following-sibling::div[1]//a')]\n",
    "    except:\n",
    "        genres = []\n",
    "\n",
    "    # Themes (Tags)\n",
    "    try:\n",
    "        tags = [a.get_attribute(\"textContent\").strip() for a in driver.find_elements(\n",
    "            By.XPATH, '//div[@id=\"tab-genres\"]//h3[span[text()=\"Themes\"]]/following-sibling::div[1]//a')]\n",
    "    except:\n",
    "        tags = []\n",
    "\n",
    "    # Cast\n",
    "    try:\n",
    "        cast_elements = driver.find_elements(By.XPATH, '//div[@class=\"cast-list text-sluglist\"]//a[@class=\"text-slug tooltip\"]')\n",
    "        cast = [el.get_attribute(\"textContent\").strip() for el in cast_elements if el.get_attribute(\"textContent\").strip()]\n",
    "    except:\n",
    "        cast = [\"N/A\"]\n",
    "\n",
    "    # Runtime\n",
    "    try:\n",
    "        footer_elem = driver.find_element(By.CLASS_NAME, \"text-footer\")\n",
    "        full_footer_text = footer_elem.get_attribute(\"textContent\") \n",
    "        runtime = re.search(r\"\\d+\", full_footer_text).group()\n",
    "    except:\n",
    "        runtime = \"N/A\"\n",
    "\n",
    "    # Subtitle/tagline\n",
    "    try:\n",
    "        subtitle = driver.find_element(By.CLASS_NAME, \"tagline\").text\n",
    "    except:\n",
    "        subtitle = \"N/A\"\n",
    "\n",
    "    # Description\n",
    "    try:\n",
    "        description_elem = driver.find_element(\n",
    "            By.XPATH, '//section//div[contains(@class, \"truncate\")]/p'\n",
    "        )\n",
    "        description = description_elem.text.strip()\n",
    "    except:\n",
    "        description = \"N/A\"\n",
    "\n",
    "    # Combine all data\n",
    "    movie_data = {\n",
    "        \"title\": title,\n",
    "        \"director\": director,\n",
    "        \"release_year\": release_year,\n",
    "        \"runtime\": runtime,\n",
    "        \"subtitle\": subtitle,\n",
    "        \"description\": description,\n",
    "        \"genres\": \"---\".join(genres),\n",
    "        \"tags\": \"---\".join(tags),\n",
    "        \"cast\": \"---\".join(cast),\n",
    "        \"watched\": watched,\n",
    "        \"avg_rating\": avg_rating,\n",
    "        \"fans\": fans,\n",
    "        \"liked\": liked\n",
    "    }\n",
    "\n",
    "    movie_data.update(rating_columns)\n",
    "\n",
    "    return movie_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d7b008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: https://letterboxd.com/film/time-for-revenge\n",
      "Scraping: https://letterboxd.com/film/japanese-borscht\n",
      "Scraping: https://letterboxd.com/film/my-old-ass\n"
     ]
    }
   ],
   "source": [
    "# hannes: I changed from chrom to safari because I don't have chrome\n",
    "#options = Options()\n",
    "#options.add_argument(\"--headless\")\n",
    "driver = webdriver.Safari()  # Hannes: might need to go back to driver = webdriver.Chrome(service=Service(), options=options\n",
    "# Hannes: in your script you use the file letterboxd_movie_data.csv but I don't see it being created by another script. I will therefore delete this section and insted load the file that your URL_extracter.ipynb script creates\n",
    "\n",
    "# Loop through movie URLs\n",
    "with open(\"letterboxd_urls.txt\", \"r\") as f:\n",
    "    movie_urls = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "\n",
    "movie_info = []\n",
    "for url in movie_urls:\n",
    "    try:\n",
    "        print(f\"Scraping: {url}\")\n",
    "        row = scrape_movie_data(driver, url)\n",
    "        movie_info.append(row)\n",
    "        df = pd.DataFrame(movie_info)\n",
    "        df.to_csv(output_file, index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to scrape {url}: {e}\")\n",
    "\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
